{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drosophila Heart OCM Image Segmentation (FlyNet 3.0) training code\n",
    "Author: Xiangping Ouyang\n",
    "\n",
    "Date: March 6th, 2024\n",
    "\n",
    "Description: This notebook contains training code to build the FlyNet3.0 model. A complete description of the model can be found within the \"An Attention LSTM U-Net model for Drosophila melanogaster heart tube segmentation in optical coherence microscopy images\" manuscript. Data directory paths need to be updated before running.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Python 3.9\n",
    "Libraries: cudatoolkit=11.8.0 cudnn=8.9.2 tensorflow=2.10.1 scikit-image opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Tensorflow and Keras libraries \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import ConvLSTM2D, TimeDistributed, Conv2D, Conv3D, BatchNormalization, \\\n",
    "    Activation, MaxPooling2D, Input, LeakyReLU, Conv2DTranspose, Concatenate, multiply, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import loss_funcs as lf\n",
    "\n",
    "# Import numpy and data management\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from random import randint\n",
    "import skimage.io\n",
    "import cv2\n",
    "\n",
    "# Import tensorboard for data visualization (optional)\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Set constants for training model \n",
    "type = \"full\"   # type of file that will be read (full: full size images)\n",
    "# Directory to the input data files (need to change)\n",
    "database_path = \"F:/Xiangping/flynet/final_tunning/training_01102024.csv\"\n",
    "# Name of your model (subject to change)\n",
    "model_name = \"flynet3.0\"\n",
    "# Directory to save training log files and output models (need to change)\n",
    "log_directory = \"F:/Xiangping/flynet/final_tunning/log/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for reading and processing input files \n",
    "def read_database(path):\n",
    "    \"\"\"\n",
    "    Get the path of the input file folder directory and split them to training and validation datasets \n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the csv file containing the input file folder directory \n",
    "\n",
    "    Returns: \n",
    "    data (np.array): array of path to all the samples \n",
    "    train_ids (np.array): array of indices for the samples in the training dataset\n",
    "    val_ids (np.array): array of indices for the samples in the testing dataset \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Filter out all the rows that have a weight less than or equal to 0\n",
    "    df = df[df['weight'] > 0]\n",
    "\n",
    "    # Save this dataframe as a csv file (file name subject to change)\n",
    "    df.to_csv(\"testdatabase.csv\", index=False)\n",
    "\n",
    "    data = df['local_dir'].tolist()\n",
    "    weights = df['weight'].tolist()\n",
    "    data=np.array(data)\n",
    "    weights=np.array(weights)\n",
    "    \n",
    "    available_ids = np.array(range(len(data)))\n",
    "\n",
    "    # Come up with a random permutation of the data\n",
    "    # Then apply the same permutation to the weights and the available ids\n",
    "    permutation = np.random.permutation(len(available_ids))\n",
    "    available_ids = available_ids[permutation]\n",
    "    weights = weights[permutation]\n",
    "\n",
    "    # adjust training and validation percentage according to the total number of input files  \n",
    "    if(len(available_ids)>=70):\n",
    "        multiplier = 0.95\n",
    "    else:\n",
    "        multiplier = 0.9\n",
    "    final_train_id = int(len(available_ids)*multiplier)\n",
    "    train_ids = available_ids[:final_train_id]\n",
    "    val_ids = available_ids[final_train_id:]\n",
    "\n",
    "    weights = weights[:final_train_id]\n",
    "    weights = weights/np.sum(weights)\n",
    "\n",
    "    return data, train_ids, val_ids, weights\n",
    "\n",
    "def getImg(path):\n",
    "    \"\"\"\n",
    "    Get the path of the full image file directory \n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the input file folder directory \n",
    "\n",
    "    Returns: \n",
    "    file_path (str): path to the full image file\n",
    "    \"\"\"\n",
    "    global type\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"img\" in the name\n",
    "    search_string = type + \"_img.tiff\"\n",
    "\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(path)\n",
    "    print(\"No resize file found\")\n",
    "\n",
    "def getMask(path):\n",
    "    \"\"\"\n",
    "    Get the path of the full mask file directory \n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the input file folder directory \n",
    "\n",
    "    Returns: \n",
    "    file_path (str): path to the full mask file\n",
    "    \"\"\"\n",
    "    global type\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"mask\" in the name\n",
    "    search_string = type + \"_mask.tiff\"\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No mask file found\")\n",
    "\n",
    "def getResizeImg(path):\n",
    "    \"\"\"\n",
    "    Get the path of the resize image file directory \n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the input file folder directory \n",
    "\n",
    "    Returns: \n",
    "    file_path (str): path to the resized image file\n",
    "    \"\"\"\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"resize_img\" in the name\n",
    "    search_string = \"resize_img.tiff\"\n",
    "\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No resize file found\")\n",
    "\n",
    "def getResizeMask(path):\n",
    "    \"\"\"\n",
    "    Get the path of the resize mask file directory \n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the input file folder directory \n",
    "\n",
    "    Returns: \n",
    "    file_path (str): path to the resized mask file\n",
    "    \"\"\"\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"resize_mask\" in the name\n",
    "    search_string = \"resize_mask.tiff\"\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No mask file found\")\n",
    "\n",
    "def centerVideo(video):\n",
    "    \"\"\"\n",
    "    Center the video by subtracting the mean of all the frames and dividing by the standard deviation\n",
    "\n",
    "    Parameters: \n",
    "    video (np.array): array of video frames\n",
    "\n",
    "    Returns: \n",
    "    centered_video (np.array): array of centered video frames \n",
    "    \"\"\"\n",
    "    mean = np.mean(video)\n",
    "    std = np.std(video)\n",
    "    centered_video = (video - mean) / std\n",
    "    return centered_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "def generateData(data, available_ids, batch_size, ws):\n",
    "    \"\"\"\n",
    "    Generate training data \n",
    "\n",
    "    Parameters: \n",
    "    data (np.array): array of paths to individual samples\n",
    "    available_ids (np.array): array of available indices\n",
    "    batch_size (int): number of samples to generate\n",
    "\n",
    "    Yield:\n",
    "    outputX (np.array): array of training samples\n",
    "    outputY (np.array): array of training labels\n",
    "    \"\"\"\n",
    "    augment = True\n",
    "    while True:\n",
    "        # Choose two random IDs from the available IDs\n",
    "        # INCREASE NUMBER OF SAMPLES HERE IF GPU MEMORY ALLOWS\n",
    "        s = choice(available_ids, size=3, replace=False, p=ws)\n",
    "        outputX = []\n",
    "        outputY = []\n",
    "        for i in s:\n",
    "            # Read the image at that ID and convert it to a numpy array\n",
    "            dir_path = data[i]\n",
    "            mask_path = getMask(dir_path)\n",
    "            resize_path = getImg(dir_path)\n",
    "            img = skimage.io.imread(resize_path)\n",
    "            img = np.array(img)\n",
    "            img = np.squeeze(img)\n",
    "           \n",
    "            # Read the mask file and convert it to a numpy array\n",
    "            img_mask=skimage.io.imread(mask_path)\n",
    "            img_mask=np.array(img_mask)\n",
    "            if(len(img_mask.shape) > 3):\n",
    "                img_mask = (img_mask[:,:,:,0]>0.5)*1.0\n",
    "            else:\n",
    "                img_mask = (img_mask>0.5)*1.0\n",
    "            \n",
    "            # Add a singleton dimension so that all images have a color channel\n",
    "            train = np.array(img)\n",
    "            train=train[...,np.newaxis]\n",
    "            y=np.array(img_mask)\n",
    "            y=y[...,np.newaxis]\n",
    "            \n",
    "            # For training samples shorten to 128 frames per step\n",
    "            last_start = train.shape[0] - batch_size\n",
    "            start_loc = randint(0, last_start)\n",
    "            end_loc = start_loc + batch_size\n",
    "            train = train[start_loc:end_loc]\n",
    "            y = y[start_loc:end_loc]\n",
    "\n",
    "            # The shape of y is [frame, height, width, 1]\n",
    "            # y is a mask with value 0 or 1, find the max and min x and y coordinates of the mask\n",
    "            max_x = np.max(np.where(y == 1)[2])\n",
    "            min_x = np.min(np.where(y == 1)[2])\n",
    "            max_y = np.max(np.where(y == 1)[1])\n",
    "            min_y = np.min(np.where(y == 1)[1])\n",
    "\n",
    "            min_x = 3 if min_x <= 15 else min_x - 12\n",
    "            min_y = 3 if min_y <= 15 else min_y - 12\n",
    "            max_x = 124 if max_x >= 112 else max_x + 12\n",
    "            max_y = 596 if max_y >= 584 else max_y + 12\n",
    "\n",
    "            low = min_y - 30 if min_y - 30 > 1 else 1\n",
    "            high = max_y + 30 if max_y + 30 < y.shape[1] - 1 else y.shape[1] - 1\n",
    "\n",
    "            # Now select the boundaries for the crop\n",
    "            # Make sure the whole mask is in the frame\n",
    "            crop_x_min = randint(2, min_x)\n",
    "            crop_x_max = randint(max_x, 125)\n",
    "            crop_y_min = randint(low, min_y)\n",
    "            crop_y_max = randint(max_y, high)\n",
    "\n",
    "            # Crop the image and mask\n",
    "            train_roi = train[:, crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
    "            y_roi = y[:, crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
    "\n",
    "            # Now interpolate the image and mask to the original size\n",
    "            train_list = []\n",
    "            y_list = []\n",
    "            for i in range(len(train_roi)):\n",
    "                train_i = cv2.resize(train_roi[i], (128, 128),interpolation=cv2.INTER_CUBIC)\n",
    "                train_list.append(train_i)\n",
    "                y_i = cv2.resize(y_roi[i], (128, 128),interpolation=cv2.INTER_CUBIC)\n",
    "                y_list.append(y_i)\n",
    "\n",
    "            train = np.array(train_list)\n",
    "            y = np.array(y_list)\n",
    "            \n",
    "            if augment:\n",
    "                # Apply random rotation/flip augmentation\n",
    "                aug = randint(0, 2) # Equal chance for each\n",
    "                if aug==0:\n",
    "                    aug_x = train\n",
    "                    aug_y = y\n",
    "                elif aug==1:\n",
    "                    aug_x = np.flip(train, 1)\n",
    "                    aug_y = np.flip(y, 1)\n",
    "                elif aug==2:\n",
    "                    aug_x = np.flip(train, 2)\n",
    "                    aug_y = np.flip(y, 2)\n",
    "                elif aug==3:\n",
    "                    aug_x = np.flip(train, 0)\n",
    "                    aug_y = np.flip(y, 0)\n",
    "                    \n",
    "                # Cast to uint8 before yield\n",
    "                train = aug_x.astype('float32')\n",
    "                y = aug_y.astype('float32')\n",
    "\n",
    "                # Normalize the image\n",
    "                train = centerVideo(train)\n",
    "\n",
    "            else:\n",
    "                train = train.astype('float32')\n",
    "                y = y.astype('float32')\n",
    "\n",
    "                # Normalize the image\n",
    "                train = centerVideo(train)\n",
    "\n",
    "            outputX.append(train)\n",
    "            outputY.append(y)\n",
    "\n",
    "        outputX = np.array(outputX)\n",
    "        outputY = np.array(outputY)\n",
    "\n",
    "        yield (outputX, outputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation data \n",
    "def readFiles(data, ids):\n",
    "    \"\"\"\n",
    "    Generate validation data \n",
    "\n",
    "    Parameters: \n",
    "    data (np.array): array of paths to individual samples\n",
    "    ids (np.array): array of available indices\n",
    "\n",
    "    Returns:\n",
    "    image (np.array): array of validation samples\n",
    "    y (np.array): array of validation labels\n",
    "    \"\"\"\n",
    "    # make an empty array to hold \n",
    "    train_list = []\n",
    "    mask_list = []\n",
    "    for i in ids:\n",
    "        dir_path = data[i]\n",
    "        mask_path = getResizeMask(dir_path)\n",
    "        resize_path = getResizeImg(dir_path)\n",
    "        img = skimage.io.imread(resize_path)\n",
    "        img = np.array(img)\n",
    "        img = np.squeeze(img)\n",
    "        \n",
    "        # Read the mask file and convert it to a numpy array\n",
    "        img_mask=skimage.io.imread(mask_path)\n",
    "        img_mask=np.array(img_mask)\n",
    "        if(len(img_mask.shape) > 3):\n",
    "            img_mask = (img_mask[:,:,:,0]>0.5)*1.0\n",
    "        else:\n",
    "            img_mask = (img_mask>0.5)*1.0\n",
    "        \n",
    "        # Add a singleton dimension so that all images have a color channel\n",
    "        length=len(img)\n",
    "        image = np.array(img)\n",
    "        image=image[:length,:,:,np.newaxis]\n",
    "        y=np.array(img_mask)\n",
    "        y=y[:length,:,:,np.newaxis]\n",
    "\n",
    "        startidx = 0\n",
    "        endidx = 32\n",
    "        for i in range(length//64):\n",
    "            train_list.append(centerVideo(image[startidx:endidx, ...].astype('float32')))\n",
    "            mask_list.append(y[startidx:endidx, ...].astype('float32'))\n",
    "            startidx += 64\n",
    "            endidx += 64\n",
    "\n",
    "    # Convert the lists into numpy arrays combining the first dimension\n",
    "    image = np.array(train_list)\n",
    "    y = np.array(mask_list)\n",
    "    \n",
    "    return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different metrics for measuring the performance of the model\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the dice coefficient between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    score (float): dice coefficient\n",
    "    \"\"\"\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = tf.cast(y_true_f, tf.float32)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the dice loss between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    loss (float): dice loss\n",
    "    \"\"\"\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the binary cross entropy dice loss between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    loss (float): binary cross entropy dice loss\n",
    "    \"\"\"\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model structure for each blocks, more details explaination can \n",
    "# be found under \"2.3 General network structure\" section from the manuscript \n",
    "def attention_block(input, num_filters, skip_features):\n",
    "    g1 = Conv2D(num_filters/2, (2,2), padding=\"same\")(input)\n",
    "    g1 = BatchNormalization()(g1)\n",
    "\n",
    "    x1 = Conv2D(num_filters/2, (1,1), padding=\"same\")(skip_features)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "\n",
    "    psi = LeakyReLU(alpha=0.2)(add([g1, x1]))\n",
    "    psi = Conv2D(1, 1, padding=\"same\")(psi)\n",
    "    psi = BatchNormalization()(psi)\n",
    "    psi = Activation('sigmoid')(psi)\n",
    "\n",
    "    out = multiply([skip_features, psi])\n",
    "    return out\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def init_block(input, num_filters):\n",
    "    x = ConvLSTM2D(num_filters, 5, padding=\"same\", return_sequences=True)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def first_block(input, num_filters):\n",
    "    x = init_block(input, num_filters)\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, num_filters, skip_features):\n",
    "    x = TimeDistributed(Conv2DTranspose(num_filters, (2, 2), strides=(2,2), padding=\"same\"))(input)\n",
    "    a = attention_block(x, num_filters, skip_features)\n",
    "    x = Concatenate()([x, a])\n",
    "    x = encoder_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def last_block(input, num_filters, skip_features):\n",
    "    x = TimeDistributed(Conv2DTranspose(num_filters, (2, 2), strides=(2,2), padding=\"same\"))(input)\n",
    "    a = attention_block(x, num_filters, skip_features)\n",
    "    x = Concatenate()([x, a])\n",
    "    x = first_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def create_model(input_shape=(None, 128, 128, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    s1 = first_block(inputs, 32)\n",
    "    p1 = TimeDistributed(MaxPooling2D((2, 2)))(s1)\n",
    "\n",
    "    s2 = encoder_block(p1, 64)\n",
    "    p2 = TimeDistributed(MaxPooling2D((2, 2)))(s2)\n",
    "\n",
    "    s3 = encoder_block(p2, 128)\n",
    "    p3 = TimeDistributed(MaxPooling2D((2, 2)))(s3)\n",
    "\n",
    "    m3 = encoder_block(p3, 256)\n",
    "\n",
    "    d3 = decoder_block(m3, 128, s3)\n",
    "\n",
    "    d2 = decoder_block(d3, 64, s2)\n",
    "\n",
    "    d1 = last_block(d2, 32, s1)\n",
    "\n",
    "    classify = Conv3D(1, (1, 1, 1), padding=\"same\", activation='sigmoid')(d1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function that will train the model\n",
    "def main():\n",
    "    # read the input files \n",
    "    data, train_ids,val_ids, ws = read_database(database_path)\n",
    "    print(f\"Length of training set: {len(train_ids)}, Length of validation set: {len(val_ids)}\")\n",
    "    \n",
    "    # prepare training\n",
    "    K.set_image_data_format('channels_last')\n",
    "    batch_size = 32\n",
    "    steps_per_epoch = len(train_ids)*10//batch_size\n",
    "    val, y_val = readFiles(data, val_ids)\n",
    "\n",
    "    # create a new model for training or load pre-trained model\n",
    "    model = create_model()\n",
    "    # model = load_model(\"pre_trained_model.h5\", custom_objects = {'dice_coeff': dice_coeff, 'bce_dice_loss': bce_dice_loss, \"focal_tversky\": lf.Semantic_loss_functions().focal_tversky, \"log_cosh_dice_loss\": lf.Semantic_loss_functions().log_cosh_dice_loss})\n",
    "    \n",
    "    # set model parameters \n",
    "    lr = 1e-4\n",
    "    loss_function = lf.Semantic_loss_functions().log_cosh_dice_loss\n",
    "    model.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer=Adam(lr),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            dice_coeff\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # start training \n",
    "    model_checkpoint = ModelCheckpoint(log_directory + model_name + \"{epoch:02d}.h5\", monitor='val_loss', save_best_only=False)\n",
    "    # uncomment this line to use tensorboard (optional)\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_directory, histogram_freq=1)\n",
    "    model.fit(generateData(data, train_ids, batch_size, ws), steps_per_epoch=steps_per_epoch, epochs=150, verbose=1, validation_data=(val, y_val), callbacks=[model_checkpoint, tensorboard_callback])\n",
    "    \n",
    "    return data, val_ids\n",
    "\n",
    "data, val = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TF2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5babbcaf2abf2b64ffc16d064d06e32e4554c2223239598db6b7c8ea919967b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
